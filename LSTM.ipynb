{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDXffiedulL4"
      },
      "source": [
        "# Mount to drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lB8mnxqYupVd",
        "outputId": "33585f67-28b6-4b04-8d00-ab5c9c131fd8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/MyDrive/ETH_EEGproject' \n",
        "root_path = '/content/gdrive/MyDrive/ETH_EEGproject'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MgDrwAdusGM"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKpwihkCqHfF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4025813f-320b-4dcc-aedd-41898a2d5521"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, Lambda\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "import pandas as pd\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from keras.layers.wrappers import TimeDistributed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CacaFjakqmG2",
        "outputId": "bf3aacf8-4f66-41ca-9198-c071d17f2100"
      },
      "source": [
        "def train_test_split_tensors(X, y, **options):\n",
        "    \"\"\"\n",
        "    encapsulation for the sklearn.model_selection.train_test_split function\n",
        "    in order to split tensors objects and return tensors as output\n",
        "\n",
        "    :param X: tensorflow.Tensor object\n",
        "    :param y: tensorflow.Tensor object\n",
        "    :dict **options: typical sklearn options are available, such as test_size and train_size\n",
        "    \"\"\"\n",
        "\n",
        "    from sklearn.model_selection import train_test_split\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X.numpy(), y.numpy(), **options)\n",
        "\n",
        "    X_train, X_test = tf.constant(X_train), tf.constant(X_test)\n",
        "    y_train, y_test = tf.constant(y_train), tf.constant(y_test)\n",
        "\n",
        "    del(train_test_split)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "\n",
        "x = tf.io.read_file(\"gdrive/MyDrive/ETH_EEGproject/tensor1_99\")\n",
        "X = tf.io.parse_tensor(x, tf.float32, name=None)\n",
        "#X *= 255\n",
        "\"\"\"\n",
        "z = tf.io.read_file(\"gdrive/MyDrive/ETH_EEGproject/tensor60_109\")\n",
        "Z = tf.io.parse_tensor(z, tf.float32, name=None)\n",
        "Z *= 255\n",
        "X = tf.concat([X,Z],axis = -1)\n",
        "\"\"\"\n",
        "X = tf.transpose(X, perm = [3,0,1,2])\n",
        "\n",
        "\"\"\"\n",
        "labels = pd.read_csv('labels.csv')\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(labels[107998:-1])\n",
        "#y = np.array([])\n",
        "y = le.transform(labels[107998:-1])\n",
        "y = y.ravel()\n",
        "\"\"\"\n",
        "\n",
        "y = np.loadtxt(\"gdrive/MyDrive/ETH_EEGproject/complete_labels.csv\", delimiter=\",\")\n",
        "#y = tf.keras.utils.to_categorical(temp[0:104400])\n",
        "y_train_num = tf.convert_to_tensor(y[0:171000], dtype=np.int64)\n",
        "\n",
        "#y = to_categorical(y, 3)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split_tensors(X, y_train_num, test_size=0.20,shuffle=False)\n",
        "\n",
        "# down sampling\n",
        "x_train_res = tf.reshape(x_train, [x_train.shape[0], 32*32*3])\n",
        "#y_train_num = np.argmax(y_train,axis=1)\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_train_down, y_train_down = rus.fit_resample(x_train_res, y_train)\n",
        "\n",
        "X_train_down = tf.reshape(X_train_down, [X_train_down.shape[0], 32, 32, 3])\n",
        "y_train_down = keras.utils.to_categorical(y_train_down)\n",
        "y_test = keras.utils.to_categorical(y_test)\n",
        "\n",
        "\"\"\"\n",
        "#further split training data for testing\n",
        "    x_train_true = x_train[0:83500,:,:,:]\n",
        "y_train_true = y_train[0:8350]\n",
        "\n",
        "x_new = x_train[83501:83520,:,:,:]\n",
        "y_new_true = y_train[83501:83520]\n",
        "\n",
        "#y_train_true = to_categorical(y_train_true, 3)\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\"\"\"\n",
        "# convert class vectors to binary class matrices\n",
        "#y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "#y_test = np_utils.to_categorical(y_test, num_classes)\n",
        "batch_size = 32\n",
        "num_classes = 3\n",
        "epochs = 100\n",
        "\n",
        "input_shape = (32, 32, 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BUR-rE4vSpM",
        "outputId": "dc382dbd-0e7b-44cd-8b00-6754982de7d2"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([20880, 32, 32, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNYD21SyNkzQ"
      },
      "source": [
        "# Proposed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1ry2pq9NmXb",
        "outputId": "93135dac-e881-4243-ba42-321696fe77f5"
      },
      "source": [
        "from keras import regularizers\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
        "#model.add(Dropout(0.1))\n",
        "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
        "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
        "\n",
        "# max pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "#model.add(Dropout(0.25))#\n",
        "\n",
        "# 2 convolutional 3 x 128\n",
        "model.add(Conv2D(128, (3, 3), activation=\"relu\"))\n",
        "model.add(Conv2D(128, (3, 3), activation=\"relu\"))\n",
        "\n",
        "# max pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "#model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation=\"relu\"))\n",
        "model.add(Conv2D(256, (3, 3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "model.add(LSTM(256, return_sequences=False))\n",
        "\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = keras.optimizers.RMSprop(lr=0.001, decay=1e-6)\n",
        "optsgd = keras.optimizers.SGD(lr=0.01, momentum=0.9)\n",
        "optadam = keras.optimizers.Adam(\n",
        "    learning_rate=0.001,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=False,\n",
        "    name=\"Adam\"\n",
        ")\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optsgd, \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(\"fitting...\")\n",
        "\n",
        "history = model.fit(X_train_down, y_train_down,\n",
        "          batch_size=16,\n",
        "          epochs=20)\n",
        "\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "y_new = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fitting...\n",
            "Epoch 1/20\n",
            "6372/6372 [==============================] - 34s 5ms/step - loss: 1.0987 - accuracy: 0.3423\n",
            "Epoch 2/20\n",
            "6372/6372 [==============================] - 34s 5ms/step - loss: 1.0945 - accuracy: 0.3616\n",
            "Epoch 3/20\n",
            "6372/6372 [==============================] - 34s 5ms/step - loss: 1.0925 - accuracy: 0.3668\n",
            "Epoch 4/20\n",
            "6372/6372 [==============================] - 34s 5ms/step - loss: 1.0912 - accuracy: 0.3694\n",
            "Epoch 5/20\n",
            "6372/6372 [==============================] - 34s 5ms/step - loss: 1.0900 - accuracy: 0.3746\n",
            "Epoch 6/20\n",
            "6372/6372 [==============================] - 34s 5ms/step - loss: 1.0888 - accuracy: 0.3773\n",
            "Epoch 7/20\n",
            "6372/6372 [==============================] - 34s 5ms/step - loss: 1.0874 - accuracy: 0.3809\n",
            "Epoch 8/20\n",
            "6372/6372 [==============================] - 34s 5ms/step - loss: 1.0857 - accuracy: 0.3836\n",
            "Epoch 9/20\n",
            "6372/6372 [==============================] - 34s 5ms/step - loss: 1.0831 - accuracy: 0.3890\n",
            "Epoch 10/20\n",
            "6372/6372 [==============================] - 34s 5ms/step - loss: 1.0809 - accuracy: 0.3926\n",
            "Epoch 11/20\n",
            "6372/6372 [==============================] - 34s 5ms/step - loss: 1.0767 - accuracy: 0.3971\n",
            "Epoch 12/20\n",
            "6372/6372 [==============================] - 35s 5ms/step - loss: 1.0705 - accuracy: 0.4081\n",
            "Epoch 13/20\n",
            "6372/6372 [==============================] - 34s 5ms/step - loss: 1.0623 - accuracy: 0.4176\n",
            "Epoch 14/20\n",
            "6372/6372 [==============================] - 34s 5ms/step - loss: 1.0510 - accuracy: 0.4305\n",
            "Epoch 15/20\n",
            "6372/6372 [==============================] - 34s 5ms/step - loss: 1.0374 - accuracy: 0.4443\n",
            "Epoch 16/20\n",
            "6372/6372 [==============================] - 34s 5ms/step - loss: 1.0203 - accuracy: 0.4607\n",
            "Epoch 17/20\n",
            "6372/6372 [==============================] - 34s 5ms/step - loss: 0.9991 - accuracy: 0.4786\n",
            "Epoch 18/20\n",
            "6372/6372 [==============================] - 33s 5ms/step - loss: 0.9754 - accuracy: 0.4982\n",
            "Epoch 19/20\n",
            "6372/6372 [==============================] - 33s 5ms/step - loss: 0.9540 - accuracy: 0.5146\n",
            "Epoch 20/20\n",
            "6372/6372 [==============================] - 33s 5ms/step - loss: 0.9301 - accuracy: 0.5339\n",
            "1069/1069 [==============================] - 3s 3ms/step - loss: 1.3034 - accuracy: 0.3682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13mwg4BTiwM6"
      },
      "source": [
        "# LSTM1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0U4nzatu6ER",
        "outputId": "32fdc2a0-aee9-46fb-aeac-a8464965c214"
      },
      "source": [
        "from keras import regularizers\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(16, (3, 3), activation=\"relu\"))\n",
        "#model.add(Dropout(0.1))\n",
        "model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
        "\n",
        "# max pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "model.add(Dropout(0.25))#\n",
        "\n",
        "# 2 convolutional 3 x 128\n",
        "model.add(Conv2D(64, (3, 3), activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "# max pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "#model.add(Dropout(0.25))\n",
        "\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "model.add(LSTM(256, return_sequences=False))\n",
        "model.add(Dense(100,kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.5))\n",
        "#model.add(Lambda(lambda x: tf.expand_dims(model.output, axis=-1)))\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = keras.optimizers.RMSprop(lr=0.001, decay=1e-6)\n",
        "optsgd = keras.optimizers.SGD(lr=0.01, momentum=0.9)\n",
        "optadam = keras.optimizers.Adam(\n",
        "    learning_rate=0.001,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=False,\n",
        "    name=\"Adam\"\n",
        ")\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optadam, \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(\"fitting...\")\n",
        "\n",
        "history = model.fit(X_train_down, y_train_down,\n",
        "          batch_size=32,\n",
        "          epochs=150)\n",
        "\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "y_new = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fitting...\n",
            "Epoch 1/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.1675 - accuracy: 0.3450\n",
            "Epoch 2/150\n",
            "3151/3151 [==============================] - 17s 5ms/step - loss: 1.1044 - accuracy: 0.3542\n",
            "Epoch 3/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.1003 - accuracy: 0.3615\n",
            "Epoch 4/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0966 - accuracy: 0.3662\n",
            "Epoch 5/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0951 - accuracy: 0.3666\n",
            "Epoch 6/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0934 - accuracy: 0.3693\n",
            "Epoch 7/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0926 - accuracy: 0.3740\n",
            "Epoch 8/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0911 - accuracy: 0.3743\n",
            "Epoch 9/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0907 - accuracy: 0.3745\n",
            "Epoch 10/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0907 - accuracy: 0.3722\n",
            "Epoch 11/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0903 - accuracy: 0.3759\n",
            "Epoch 12/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0902 - accuracy: 0.3745\n",
            "Epoch 13/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0900 - accuracy: 0.3752\n",
            "Epoch 14/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0901 - accuracy: 0.3754\n",
            "Epoch 15/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0898 - accuracy: 0.3747\n",
            "Epoch 16/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0897 - accuracy: 0.3746\n",
            "Epoch 17/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0890 - accuracy: 0.3753\n",
            "Epoch 18/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0892 - accuracy: 0.3787\n",
            "Epoch 19/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0886 - accuracy: 0.3788\n",
            "Epoch 20/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0883 - accuracy: 0.3787\n",
            "Epoch 21/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0881 - accuracy: 0.3798\n",
            "Epoch 22/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0884 - accuracy: 0.3801\n",
            "Epoch 23/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0880 - accuracy: 0.3798\n",
            "Epoch 24/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0879 - accuracy: 0.3801\n",
            "Epoch 25/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0875 - accuracy: 0.3803\n",
            "Epoch 26/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0870 - accuracy: 0.3808\n",
            "Epoch 27/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0870 - accuracy: 0.3822\n",
            "Epoch 28/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0867 - accuracy: 0.3801\n",
            "Epoch 29/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0863 - accuracy: 0.3839\n",
            "Epoch 30/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0862 - accuracy: 0.3850\n",
            "Epoch 31/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0859 - accuracy: 0.3877\n",
            "Epoch 32/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0853 - accuracy: 0.3848\n",
            "Epoch 33/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0850 - accuracy: 0.3867\n",
            "Epoch 34/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0851 - accuracy: 0.3853\n",
            "Epoch 35/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0848 - accuracy: 0.3874\n",
            "Epoch 36/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0848 - accuracy: 0.3861\n",
            "Epoch 37/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0844 - accuracy: 0.3880\n",
            "Epoch 38/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0837 - accuracy: 0.3867\n",
            "Epoch 39/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0835 - accuracy: 0.3894\n",
            "Epoch 40/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0831 - accuracy: 0.3897\n",
            "Epoch 41/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0830 - accuracy: 0.3909\n",
            "Epoch 42/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0826 - accuracy: 0.3905\n",
            "Epoch 43/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0822 - accuracy: 0.3901\n",
            "Epoch 44/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0822 - accuracy: 0.3915\n",
            "Epoch 45/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0812 - accuracy: 0.3942\n",
            "Epoch 46/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0809 - accuracy: 0.3923\n",
            "Epoch 47/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0802 - accuracy: 0.3956\n",
            "Epoch 48/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0791 - accuracy: 0.3977\n",
            "Epoch 49/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0788 - accuracy: 0.3969\n",
            "Epoch 50/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0778 - accuracy: 0.4001\n",
            "Epoch 51/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0778 - accuracy: 0.4010\n",
            "Epoch 52/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0759 - accuracy: 0.4042\n",
            "Epoch 53/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0760 - accuracy: 0.4007\n",
            "Epoch 54/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0749 - accuracy: 0.4019\n",
            "Epoch 55/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0737 - accuracy: 0.4049\n",
            "Epoch 56/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0727 - accuracy: 0.4058\n",
            "Epoch 57/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0713 - accuracy: 0.4093\n",
            "Epoch 58/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0698 - accuracy: 0.4108\n",
            "Epoch 59/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0679 - accuracy: 0.4122\n",
            "Epoch 60/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0676 - accuracy: 0.4122\n",
            "Epoch 61/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0651 - accuracy: 0.4162\n",
            "Epoch 62/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0641 - accuracy: 0.4178\n",
            "Epoch 63/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0623 - accuracy: 0.4190\n",
            "Epoch 64/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0599 - accuracy: 0.4210\n",
            "Epoch 65/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0585 - accuracy: 0.4231\n",
            "Epoch 66/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0560 - accuracy: 0.4263\n",
            "Epoch 67/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0547 - accuracy: 0.4279\n",
            "Epoch 68/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0516 - accuracy: 0.4315\n",
            "Epoch 69/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0512 - accuracy: 0.4323\n",
            "Epoch 70/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0491 - accuracy: 0.4330\n",
            "Epoch 71/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0463 - accuracy: 0.4360\n",
            "Epoch 72/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0438 - accuracy: 0.4387\n",
            "Epoch 73/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0417 - accuracy: 0.4415\n",
            "Epoch 74/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0384 - accuracy: 0.4428\n",
            "Epoch 75/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0378 - accuracy: 0.4458\n",
            "Epoch 76/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0327 - accuracy: 0.4476\n",
            "Epoch 77/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0313 - accuracy: 0.4494\n",
            "Epoch 78/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0289 - accuracy: 0.4529\n",
            "Epoch 79/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0273 - accuracy: 0.4536\n",
            "Epoch 80/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0245 - accuracy: 0.4575\n",
            "Epoch 81/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0204 - accuracy: 0.4597\n",
            "Epoch 82/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0187 - accuracy: 0.4624\n",
            "Epoch 83/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0153 - accuracy: 0.4670\n",
            "Epoch 84/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0120 - accuracy: 0.4666\n",
            "Epoch 85/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0091 - accuracy: 0.4715\n",
            "Epoch 86/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0106 - accuracy: 0.4660\n",
            "Epoch 87/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 1.0027 - accuracy: 0.4762\n",
            "Epoch 88/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.9996 - accuracy: 0.4786\n",
            "Epoch 89/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.9960 - accuracy: 0.4798\n",
            "Epoch 90/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.9935 - accuracy: 0.4833\n",
            "Epoch 91/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.9890 - accuracy: 0.4847\n",
            "Epoch 92/150\n",
            "3151/3151 [==============================] - 15s 5ms/step - loss: 0.9861 - accuracy: 0.4884\n",
            "Epoch 93/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.9838 - accuracy: 0.4900\n",
            "Epoch 94/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.9794 - accuracy: 0.4937\n",
            "Epoch 95/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.9779 - accuracy: 0.4979\n",
            "Epoch 96/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.9748 - accuracy: 0.4987\n",
            "Epoch 97/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.9724 - accuracy: 0.4996\n",
            "Epoch 98/150\n",
            "3151/3151 [==============================] - 15s 5ms/step - loss: 0.9692 - accuracy: 0.5021\n",
            "Epoch 99/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.9663 - accuracy: 0.5054\n",
            "Epoch 100/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.9608 - accuracy: 0.5080\n",
            "Epoch 101/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.9580 - accuracy: 0.5105\n",
            "Epoch 102/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.9558 - accuracy: 0.5124\n",
            "Epoch 103/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.9508 - accuracy: 0.5181\n",
            "Epoch 104/150\n",
            "3151/3151 [==============================] - 15s 5ms/step - loss: 0.9475 - accuracy: 0.5170\n",
            "Epoch 105/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.9445 - accuracy: 0.5204\n",
            "Epoch 106/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.9423 - accuracy: 0.5224\n",
            "Epoch 107/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.9384 - accuracy: 0.5253\n",
            "Epoch 108/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.9348 - accuracy: 0.5274\n",
            "Epoch 109/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.9301 - accuracy: 0.5293\n",
            "Epoch 110/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.9277 - accuracy: 0.5324\n",
            "Epoch 111/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.9256 - accuracy: 0.5351\n",
            "Epoch 112/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.9194 - accuracy: 0.5374\n",
            "Epoch 113/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.9195 - accuracy: 0.5365\n",
            "Epoch 114/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.9134 - accuracy: 0.5428\n",
            "Epoch 115/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.9121 - accuracy: 0.5437\n",
            "Epoch 116/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.9113 - accuracy: 0.5433\n",
            "Epoch 117/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.9073 - accuracy: 0.5474\n",
            "Epoch 118/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.9020 - accuracy: 0.5499\n",
            "Epoch 119/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8991 - accuracy: 0.5523\n",
            "Epoch 120/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8983 - accuracy: 0.5535\n",
            "Epoch 121/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8947 - accuracy: 0.5555\n",
            "Epoch 122/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8891 - accuracy: 0.5596\n",
            "Epoch 123/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8894 - accuracy: 0.5603\n",
            "Epoch 124/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8839 - accuracy: 0.5620\n",
            "Epoch 125/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8800 - accuracy: 0.5670\n",
            "Epoch 126/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8804 - accuracy: 0.5651\n",
            "Epoch 127/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8766 - accuracy: 0.5677\n",
            "Epoch 128/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8723 - accuracy: 0.5718\n",
            "Epoch 129/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8708 - accuracy: 0.5721\n",
            "Epoch 130/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8698 - accuracy: 0.5746\n",
            "Epoch 131/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8670 - accuracy: 0.5755\n",
            "Epoch 132/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8596 - accuracy: 0.5804\n",
            "Epoch 133/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8562 - accuracy: 0.5811\n",
            "Epoch 134/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8553 - accuracy: 0.5829\n",
            "Epoch 135/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8546 - accuracy: 0.5809\n",
            "Epoch 136/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8493 - accuracy: 0.5859\n",
            "Epoch 137/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8470 - accuracy: 0.5886\n",
            "Epoch 138/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8424 - accuracy: 0.5910\n",
            "Epoch 139/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8378 - accuracy: 0.5939\n",
            "Epoch 140/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8321 - accuracy: 0.5964\n",
            "Epoch 141/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8308 - accuracy: 0.5989\n",
            "Epoch 142/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8282 - accuracy: 0.6002\n",
            "Epoch 143/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8261 - accuracy: 0.6038\n",
            "Epoch 144/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8252 - accuracy: 0.6013\n",
            "Epoch 145/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8188 - accuracy: 0.6081\n",
            "Epoch 146/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8152 - accuracy: 0.6076\n",
            "Epoch 147/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8162 - accuracy: 0.6086\n",
            "Epoch 148/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8099 - accuracy: 0.6119\n",
            "Epoch 149/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8092 - accuracy: 0.6104\n",
            "Epoch 150/150\n",
            "3151/3151 [==============================] - 16s 5ms/step - loss: 0.8083 - accuracy: 0.6120\n",
            "1058/1058 [==============================] - 3s 3ms/step - loss: 1.5186 - accuracy: 0.3931\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0D7UGlrezar",
        "outputId": "1075456a-a787-423a-8317-7b8832e108b2"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "y_new = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1069/1069 [==============================] - 3s 3ms/step - loss: 1.3034 - accuracy: 0.3682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxA3wNORAsRZ",
        "outputId": "df02b400-9ba6-4c70-89cc-ca79dd3199bb"
      },
      "source": [
        "from collections import Counter\n",
        "Counter(np.argmax(y_new,axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 14105, 1: 10038, 2: 10057})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "Xk3k2GDtAwEY",
        "outputId": "6c61139c-aeb4-45d6-af6b-639ac9c17908"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "ivwAZX6t0-z5",
        "outputId": "20e2cea1-d833-48ee-8611-8c724f5e83bb"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-3caefa261807>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   2349\u001b[0m     \"\"\"\n\u001b[1;32m   2350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2351\u001b[0;31m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[1;32m   2352\u001b[0m                        \u001b[0;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2353\u001b[0m                        \u001b[0;34m'`fit()` with some data, or specify '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny2PgsUfo6sv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXtMoB11v6mn"
      },
      "source": [
        "Another location and weight of dropout layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXgKH3WxwA8S",
        "outputId": "c0bd1478-92af-4abb-eb5e-992976d2ec80"
      },
      "source": [
        "from keras import regularizers\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(16, (3, 3), activation=\"relu\"))\n",
        "#model.add(Dropout(0.1))\n",
        "model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
        "\n",
        "# max pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "model.add(Dropout(0.25))#\n",
        "model.add(Conv2D(64, (3, 3), activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)))\n",
        "\n",
        "# max pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "model.add(LSTM(256, return_sequences=False))\n",
        "model.add(Dense(100,kernel_regularizer=regularizers.l2(0.001)))\n",
        "##model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "#model.add(Lambda(lambda x: tf.expand_dims(model.output, axis=-1)))\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = keras.optimizers.RMSprop(lr=0.001, decay=1e-6)\n",
        "optsgd = keras.optimizers.SGD(lr=0.01, momentum=0.9)\n",
        "optadam = keras.optimizers.Adam(\n",
        "    learning_rate=0.001,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=False,\n",
        "    name=\"Adam\"\n",
        ")\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optadam, \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(\"fitting...\")\n",
        "\n",
        "history = model.fit(X_train_down, y_train_down,\n",
        "          batch_size=32,\n",
        "          epochs=150)\n",
        "\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "y_new = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fitting...\n",
            "Epoch 1/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.1622 - accuracy: 0.3540\n",
            "Epoch 2/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0974 - accuracy: 0.3628\n",
            "Epoch 3/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0932 - accuracy: 0.3702\n",
            "Epoch 4/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0928 - accuracy: 0.3696\n",
            "Epoch 5/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0923 - accuracy: 0.3729\n",
            "Epoch 6/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0911 - accuracy: 0.3731\n",
            "Epoch 7/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0911 - accuracy: 0.3726\n",
            "Epoch 8/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0904 - accuracy: 0.3764\n",
            "Epoch 9/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0905 - accuracy: 0.3744\n",
            "Epoch 10/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0904 - accuracy: 0.3763\n",
            "Epoch 11/150\n",
            "1944/1944 [==============================] - 12s 6ms/step - loss: 1.0906 - accuracy: 0.3741\n",
            "Epoch 12/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0902 - accuracy: 0.3747\n",
            "Epoch 13/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0901 - accuracy: 0.3763\n",
            "Epoch 14/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0899 - accuracy: 0.3749\n",
            "Epoch 15/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0894 - accuracy: 0.3791\n",
            "Epoch 16/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0890 - accuracy: 0.3788\n",
            "Epoch 17/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0890 - accuracy: 0.3755\n",
            "Epoch 18/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0890 - accuracy: 0.3791\n",
            "Epoch 19/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0887 - accuracy: 0.3764\n",
            "Epoch 20/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0887 - accuracy: 0.3805\n",
            "Epoch 21/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0880 - accuracy: 0.3785\n",
            "Epoch 22/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0883 - accuracy: 0.3781\n",
            "Epoch 23/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0884 - accuracy: 0.3773\n",
            "Epoch 24/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0878 - accuracy: 0.3779\n",
            "Epoch 25/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0879 - accuracy: 0.3791\n",
            "Epoch 26/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0879 - accuracy: 0.3795\n",
            "Epoch 27/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0877 - accuracy: 0.3793\n",
            "Epoch 28/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0876 - accuracy: 0.3802\n",
            "Epoch 29/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0875 - accuracy: 0.3817\n",
            "Epoch 30/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0878 - accuracy: 0.3772\n",
            "Epoch 31/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0872 - accuracy: 0.3817\n",
            "Epoch 32/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0873 - accuracy: 0.3806\n",
            "Epoch 33/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0868 - accuracy: 0.3809\n",
            "Epoch 34/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0870 - accuracy: 0.3793\n",
            "Epoch 35/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0869 - accuracy: 0.3819\n",
            "Epoch 36/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0870 - accuracy: 0.3818\n",
            "Epoch 37/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0869 - accuracy: 0.3816\n",
            "Epoch 38/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0861 - accuracy: 0.3807\n",
            "Epoch 39/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0866 - accuracy: 0.3809\n",
            "Epoch 40/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0862 - accuracy: 0.3843\n",
            "Epoch 41/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0859 - accuracy: 0.3834\n",
            "Epoch 42/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0855 - accuracy: 0.3828\n",
            "Epoch 43/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0854 - accuracy: 0.3846\n",
            "Epoch 44/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0856 - accuracy: 0.3834\n",
            "Epoch 45/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0851 - accuracy: 0.3831\n",
            "Epoch 46/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0851 - accuracy: 0.3837\n",
            "Epoch 47/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0854 - accuracy: 0.3846\n",
            "Epoch 48/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0849 - accuracy: 0.3855\n",
            "Epoch 49/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0846 - accuracy: 0.3852\n",
            "Epoch 50/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0846 - accuracy: 0.3816\n",
            "Epoch 51/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0843 - accuracy: 0.3857\n",
            "Epoch 52/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0836 - accuracy: 0.3865\n",
            "Epoch 53/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0840 - accuracy: 0.3847\n",
            "Epoch 54/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0842 - accuracy: 0.3849\n",
            "Epoch 55/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0839 - accuracy: 0.3878\n",
            "Epoch 56/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0840 - accuracy: 0.3840\n",
            "Epoch 57/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0840 - accuracy: 0.3849\n",
            "Epoch 58/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0838 - accuracy: 0.3875\n",
            "Epoch 59/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0834 - accuracy: 0.3879\n",
            "Epoch 60/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0832 - accuracy: 0.3854\n",
            "Epoch 61/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0827 - accuracy: 0.3894\n",
            "Epoch 62/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0832 - accuracy: 0.3871\n",
            "Epoch 63/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0832 - accuracy: 0.3865\n",
            "Epoch 64/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0832 - accuracy: 0.3852\n",
            "Epoch 65/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0823 - accuracy: 0.3875\n",
            "Epoch 66/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0823 - accuracy: 0.3890\n",
            "Epoch 67/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0827 - accuracy: 0.3869\n",
            "Epoch 68/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0823 - accuracy: 0.3895\n",
            "Epoch 69/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0818 - accuracy: 0.3898\n",
            "Epoch 70/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0823 - accuracy: 0.3883\n",
            "Epoch 71/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0820 - accuracy: 0.3902\n",
            "Epoch 72/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0816 - accuracy: 0.3881\n",
            "Epoch 73/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0814 - accuracy: 0.3895\n",
            "Epoch 74/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0814 - accuracy: 0.3896\n",
            "Epoch 75/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0814 - accuracy: 0.3888\n",
            "Epoch 76/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0820 - accuracy: 0.3907\n",
            "Epoch 77/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0817 - accuracy: 0.3897\n",
            "Epoch 78/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0811 - accuracy: 0.3895\n",
            "Epoch 79/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0811 - accuracy: 0.3892\n",
            "Epoch 80/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0808 - accuracy: 0.3928\n",
            "Epoch 81/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0813 - accuracy: 0.3926\n",
            "Epoch 82/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0810 - accuracy: 0.3922\n",
            "Epoch 83/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0814 - accuracy: 0.3904\n",
            "Epoch 84/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0805 - accuracy: 0.3903\n",
            "Epoch 85/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0808 - accuracy: 0.3900\n",
            "Epoch 86/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0806 - accuracy: 0.3872\n",
            "Epoch 87/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0805 - accuracy: 0.3913\n",
            "Epoch 88/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0805 - accuracy: 0.3927\n",
            "Epoch 89/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0801 - accuracy: 0.3897\n",
            "Epoch 90/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0798 - accuracy: 0.3936\n",
            "Epoch 91/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0805 - accuracy: 0.3916\n",
            "Epoch 92/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0799 - accuracy: 0.3900\n",
            "Epoch 93/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0797 - accuracy: 0.3918\n",
            "Epoch 94/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0795 - accuracy: 0.3903\n",
            "Epoch 95/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0801 - accuracy: 0.3873\n",
            "Epoch 96/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0790 - accuracy: 0.3922\n",
            "Epoch 97/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0791 - accuracy: 0.3903\n",
            "Epoch 98/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0783 - accuracy: 0.3924\n",
            "Epoch 99/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0794 - accuracy: 0.3933\n",
            "Epoch 100/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0786 - accuracy: 0.3900\n",
            "Epoch 101/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0795 - accuracy: 0.3900\n",
            "Epoch 102/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0793 - accuracy: 0.3917\n",
            "Epoch 103/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0789 - accuracy: 0.3923\n",
            "Epoch 104/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0792 - accuracy: 0.3909\n",
            "Epoch 105/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0779 - accuracy: 0.3910\n",
            "Epoch 106/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0784 - accuracy: 0.3941\n",
            "Epoch 107/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0786 - accuracy: 0.3928\n",
            "Epoch 108/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0777 - accuracy: 0.3938\n",
            "Epoch 109/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0787 - accuracy: 0.3952\n",
            "Epoch 110/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0776 - accuracy: 0.3934\n",
            "Epoch 111/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0778 - accuracy: 0.3925\n",
            "Epoch 112/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0773 - accuracy: 0.3959\n",
            "Epoch 113/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0772 - accuracy: 0.3952\n",
            "Epoch 114/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0773 - accuracy: 0.3943\n",
            "Epoch 115/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0787 - accuracy: 0.3926\n",
            "Epoch 116/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0767 - accuracy: 0.3949\n",
            "Epoch 117/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0774 - accuracy: 0.3957\n",
            "Epoch 118/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0771 - accuracy: 0.3952\n",
            "Epoch 119/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0766 - accuracy: 0.3973\n",
            "Epoch 120/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0768 - accuracy: 0.3933\n",
            "Epoch 121/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0766 - accuracy: 0.3956\n",
            "Epoch 122/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0768 - accuracy: 0.3958\n",
            "Epoch 123/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0764 - accuracy: 0.3930\n",
            "Epoch 124/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0762 - accuracy: 0.3955\n",
            "Epoch 125/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0757 - accuracy: 0.3958\n",
            "Epoch 126/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0759 - accuracy: 0.3969\n",
            "Epoch 127/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0763 - accuracy: 0.3960\n",
            "Epoch 128/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0761 - accuracy: 0.3958\n",
            "Epoch 129/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0760 - accuracy: 0.3968\n",
            "Epoch 130/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0756 - accuracy: 0.3958\n",
            "Epoch 131/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0749 - accuracy: 0.3982\n",
            "Epoch 132/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0754 - accuracy: 0.3963\n",
            "Epoch 133/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0744 - accuracy: 0.3984\n",
            "Epoch 134/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0748 - accuracy: 0.3979\n",
            "Epoch 135/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0751 - accuracy: 0.3969\n",
            "Epoch 136/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0739 - accuracy: 0.3984\n",
            "Epoch 137/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0753 - accuracy: 0.3918\n",
            "Epoch 138/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0737 - accuracy: 0.3982\n",
            "Epoch 139/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0751 - accuracy: 0.3964\n",
            "Epoch 140/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0744 - accuracy: 0.3977\n",
            "Epoch 141/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0732 - accuracy: 0.4008\n",
            "Epoch 142/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0742 - accuracy: 0.3989\n",
            "Epoch 143/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0738 - accuracy: 0.3989\n",
            "Epoch 144/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0734 - accuracy: 0.3972\n",
            "Epoch 145/150\n",
            "1944/1944 [==============================] - 11s 6ms/step - loss: 1.0733 - accuracy: 0.4015\n",
            "Epoch 146/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0733 - accuracy: 0.3991\n",
            "Epoch 147/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0727 - accuracy: 0.4017\n",
            "Epoch 148/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0731 - accuracy: 0.3992\n",
            "Epoch 149/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0722 - accuracy: 0.4007\n",
            "Epoch 150/150\n",
            "1944/1944 [==============================] - 11s 5ms/step - loss: 1.0728 - accuracy: 0.4010\n",
            "653/653 [==============================] - 2s 3ms/step - loss: 1.1264 - accuracy: 0.3780\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "025lV-dm5zPl",
        "outputId": "d98d9e1a-c508-4698-f0b5-7eb172b01ce9"
      },
      "source": [
        "from collections import Counter\n",
        "Counter(np.argmax(y_new,axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 6880, 1: 13996, 2: 4})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FGVAResqol8"
      },
      "source": [
        "The network below overfits (0.8) and returns test score of 0.39 (without dropout in between dense layers)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SspOJFvyqkYg"
      },
      "source": [
        "from keras import regularizers\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(16, (3, 3), activation=\"relu\"))\n",
        "#model.add(Dropout(0.1))\n",
        "model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
        "\n",
        "# max pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "model.add(Dropout(0.25))#\n",
        "\n",
        "# 2 convolutional 3 x 128\n",
        "model.add(Conv2D(64, (3, 3), activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)))\n",
        "\n",
        "# max pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "#model.add(Dropout(0.25))\n",
        "\n",
        "# 2x convolutional 3 x 256\n",
        "#model.add(Conv2D(256, (3, 3), activation=\"relu\"))\n",
        "\n",
        "# max pooling\n",
        "#model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "#model.add(Dropout(0.25))\n",
        "\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "model.add(LSTM(256, return_sequences=False))\n",
        "model.add(Dense(100,kernel_regularizer=regularizers.l2(0.001)))\n",
        "##model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.5))\n",
        "#model.add(Lambda(lambda x: tf.expand_dims(model.output, axis=-1)))\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQow7hWp_pEs"
      },
      "source": [
        "# LSTM 2 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "dY2BGgFO_sjr",
        "outputId": "efd6f0c4-b866-4abb-f812-626c4b67ad62"
      },
      "source": [
        "# from https://github.com/hauke-d/cnn-eeg/blob/master/models.py\n",
        "from keras import regularizers\n",
        "from keras.layers import AveragePooling2D\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation=\"relu\", kernel_regularizer=regularizers.l1(0.01), padding=\"same\", input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation=\"relu\", kernel_regularizer=regularizers.l1(0.01), padding=\"valid\"))\n",
        "model.add(AveragePooling2D((3, 1), strides=(5, 1)))\n",
        "model.add(TimeDistributed(Flatten()))\n",
        "model.add(LSTM(40, activation=\"sigmoid\", dropout=0.25, return_sequences=False))\n",
        "model.add(Dense(3, activation=\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
        "\n",
        "history = model.fit(X_train_down, y_train_down,\n",
        "          batch_size=32,\n",
        "          epochs=30)\n",
        "\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "\n",
        "y_new = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/30\n",
            "1944/1944 [==============================] - 33s 17ms/step - loss: 1.2892 - acc: 0.3332\n",
            "Epoch 2/30\n",
            "1944/1944 [==============================] - 32s 17ms/step - loss: 1.1934 - acc: 0.3354\n",
            "Epoch 3/30\n",
            "1944/1944 [==============================] - 32s 17ms/step - loss: 1.1935 - acc: 0.3295\n",
            "Epoch 4/30\n",
            "1944/1944 [==============================] - 32s 16ms/step - loss: 1.1934 - acc: 0.3318\n",
            "Epoch 5/30\n",
            " 393/1944 [=====>........................] - ETA: 26s - loss: 1.1932 - acc: 0.3384"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-b0401172e77b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m history = model.fit(X_train_down, y_train_down,\n\u001b[1;32m     14\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m           epochs=30)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2aeSwWsA7jy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}